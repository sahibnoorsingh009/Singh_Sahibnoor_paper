# -*- coding: utf-8 -*-
"""EDA1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bWS-NWbnMLBj7FfUvg87M4VEVj6Lrahs
"""

import pandas as pd

# Load the dataset
file_path = "/content/drive/MyDrive/Updated_OLID_Dataset_with_Binary_subtask_a.csv"
df = pd.read_csv(file_path)

import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud

# Drop rows with missing cleaned_tweet values
df = df.dropna(subset=["cleaned_tweet"])

# Compute tweet length (number of words per tweet)
df["tweet_length"] = df["cleaned_tweet"].apply(lambda x: len(x.split()))

# Separate text for word clouds
offensive_text = " ".join(df[df["subtask_a"] == 1]["cleaned_tweet"])
non_offensive_text = " ".join(df[df["subtask_a"] == 0]["cleaned_tweet"])

# --- MAIN FIGURE: Statistical Plots ---
fig, axes = plt.subplots(1, 3, figsize=(18, 5))  # 1 row, 3 columns

# --- PLOT 1: Sentiment Distribution ---
sns.countplot(ax=axes[0], x=df["subtask_a"], palette="viridis")
axes[0].set_xticks([0, 1])
axes[0].set_xticklabels(["Not Offensive (0)", "Offensive (1)"])
axes[0].set_xlabel("Sentiment")
axes[0].set_ylabel("Tweet Count")
axes[0].set_title("Distribution of Sentiment Labels", fontsize=12, fontweight="bold")

# --- PLOT 2: Tweet Length Distribution (Histogram) ---
sns.histplot(ax=axes[1], data=df["tweet_length"], bins=30, kde=True, color="blue")
axes[1].set_xlabel("Number of Words per Tweet")
axes[1].set_ylabel("Frequency")
axes[1].set_title("Distribution of Words per Tweet", fontsize=12, fontweight="bold")

# --- PLOT 3: Tweet Length by Sentiment (Boxplot) ---
sns.boxplot(ax=axes[2], x=df["subtask_a"], y=df["tweet_length"], palette="coolwarm")
axes[2].set_xticks([0, 1])
axes[2].set_xticklabels(["Not Offensive (0)", "Offensive (1)"])
axes[2].set_xlabel("Sentiment")
axes[2].set_ylabel("Number of Words in Tweet")
axes[2].set_title("Tweet Length Distribution by Sentiment", fontsize=12, fontweight="bold")

plt.tight_layout()
plt.show()

# --- WORD CLOUDS TOGETHER ---
fig, ax = plt.subplots(1, 2, figsize=(15, 6))

wordcloud_offensive = WordCloud(width=800, height=400, background_color="white").generate(offensive_text)
ax[0].imshow(wordcloud_offensive, interpolation="bilinear")
ax[0].set_title("Word Cloud - Offensive Tweets", fontsize=12, fontweight="bold")
ax[0].axis("off")

wordcloud_non_offensive = WordCloud(width=800, height=400, background_color="white").generate(non_offensive_text)
ax[1].imshow(wordcloud_non_offensive, interpolation="bilinear")
ax[1].set_title("Word Cloud - Non-Offensive Tweets", fontsize=12, fontweight="bold")
ax[1].axis("off")

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

pred = pd.read_csv("/content/drive/MyDrive/election2024_data.csv")
# Convert the 'date' column to datetime if it's not already
pred['date'] = pd.to_datetime(pred['date'])

# Ensure all values in "clean_text" are strings and handle missing values
pred["clean_text"] = pred["clean_text"].fillna("").astype(str)

# Add a new column for tweet length
pred["tweet_length"] = pred["clean_text"].apply(lambda x: len(x.split()))

# Count the occurrences of each party label
party_distribution = pred['party'].value_counts()

# Group by date and party, then count occurrences
time_series_data = pred.groupby(['date', 'party']).size().unstack(fill_value=0)

# Set Seaborn theme
sns.set_theme(style="whitegrid")

# --- Create a compact figure with subplots ---
fig, axes = plt.subplots(1, 3, figsize=(18, 5))  # 1 row, 3 columns for compact layout

# --- PLOT 1: Bar Chart - Distribution of Predicted Party Labels ---
sns.barplot(ax=axes[0], x=party_distribution.index, y=party_distribution.values, palette="pastel")
axes[0].set_xlabel('Party', fontsize=12)
axes[0].set_ylabel('Count', fontsize=12)
axes[0].set_title('Party Label Distribution', fontsize=14, fontweight='bold')
axes[0].tick_params(axis='x', rotation=45)

# --- PLOT 2: Time Series - Party Mentions Over Time ---
for party in time_series_data.columns:
    sns.lineplot(ax=axes[1], x=time_series_data.index, y=time_series_data[party], label=party)
axes[1].set_xlabel('Date', fontsize=12)
axes[1].set_ylabel('Count', fontsize=12)
axes[1].set_title('Time Series of Party Mentions', fontsize=14, fontweight='bold')
axes[1].legend(title='Party', fontsize=10)
axes[1].tick_params(axis='x', rotation=45)

# --- PLOT 3: Histogram - Distribution of Tweet Lengths ---
sns.histplot(ax=axes[2], data=pred["tweet_length"], bins=30, kde=True, color="pink")
axes[2].set_xlabel("Tweet Length (Words)", fontsize=12)
axes[2].set_ylabel("Frequency", fontsize=12)
axes[2].set_title("Tweet Length Distribution", fontsize=14, fontweight='bold')

# Adjust layout for compact and clean visualization
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import MultinomialNB
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Load the dataset
df = pd.read_csv("/content/drive/MyDrive/Updated_OLID_Dataset_with_Binary_subtask_a.csv")

# Drop any rows where cleaned_tweet is missing
df.dropna(subset=["cleaned_tweet"], inplace=True)

# Define features (X) and target (y)
X = df["cleaned_tweet"]
y = df["subtask_a"]  # Binary sentiment label: 0 = Not Offensive, 1 = Offensive

# Train/Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# TF-IDF Vectorization
tfidf = TfidfVectorizer(
    max_df=0.95,
    min_df=2,
    ngram_range=(1,2),
    stop_words="english"
)

# Fit the vectorizer on the training set, then transform both training and test sets
X_train_tfidf = tfidf.fit_transform(X_train)
X_test_tfidf = tfidf.transform(X_test)

# Model Building and Evaluation
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000, random_state=42),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "Naive Bayes": MultinomialNB(),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric="logloss", random_state=42)
}

# Store results for visualization
model_names = []
accuracies = []

plt.figure(figsize=(15, 10))

for idx, (model_name, model) in enumerate(models.items()):
    model.fit(X_train_tfidf, y_train)
    y_pred = model.predict(X_test_tfidf)

    # Store accuracy
    acc = accuracy_score(y_test, y_pred)
    model_names.append(model_name)
    accuracies.append(acc)



    # Plot Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    plt.subplot(2, 2, idx + 1)
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=['Not Offensive', 'Offensive'], yticklabels=['Not Offensive', 'Offensive'])
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.title(f"Confusion Matrix - {model_name}")

# Show all confusion matrices
plt.tight_layout()
plt.show()

# Plot model performance (accuracy)
plt.figure(figsize=(10, 5))
sns.barplot(x=accuracies, y=model_names, palette="viridis")
plt.xlabel("Accuracy")
plt.ylabel("Model")
plt.title("Model Performance Comparison")
plt.xlim(0, 1)
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load dataset
file_path = "/content/drive/MyDrive/new_data_with_sentiment.csv"
df = pd.read_csv(file_path)

# Convert 'date' column to datetime format
df["date"] = pd.to_datetime(df["date"])

# Get the top 5 most frequent 'in_reply_to_screen_name'
top_5_reply_to = df['in_reply_to_screen_name'].value_counts().head(5).index

# Filter data for the top 5
filtered_df = df[df['in_reply_to_screen_name'].isin(top_5_reply_to)]

# Compute offensive sentiment distribution
sentiment_1_distribution = (
    filtered_df[filtered_df['sentiment'] == 1]['in_reply_to_screen_name'].value_counts()
)

# Aggregate offensive sentiment over time
offensive_df = df[df['sentiment'] == 1]
offensive_sentiment_over_time = offensive_df.groupby('date').size()

# Offensive sentiment trend by top 5 reply-to accounts
offensive_sentiment_by_top5_reply_time = offensive_df[
    offensive_df["in_reply_to_screen_name"].isin(top_5_reply_to)
].groupby(['date', 'in_reply_to_screen_name']).size().unstack()

# Offensive sentiment trend by party
offensive_sentiment_by_party_time = offensive_df.groupby(['date', 'party']).size().unstack()

# --- PLOT FIGURE WITH 4 SUBPLOTS ---
fig, axes = plt.subplots(2, 2, figsize=(18, 12))

# --- PLOT 1: Offensive Sentiment Distribution Among Top 5 Reply-To Accounts ---
sns.barplot(
    ax=axes[0, 0], x=sentiment_1_distribution.index, y=sentiment_1_distribution.values,
    palette="Reds_r"
)
axes[0, 0].set_title("Top 5 Reply-To Accounts with Offensive Sentiment", fontsize=14, fontweight='bold')
axes[0, 0].set_xlabel("Reply-To Screen Name", fontsize=12)
axes[0, 0].set_ylabel("Count of Offensive Tweets", fontsize=12)
axes[0, 0].tick_params(axis='x', rotation=45)

# --- PLOT 2: Overall Offensive Sentiment Trend Over Time ---
axes[0, 1].plot(offensive_sentiment_over_time, marker='o', linestyle='-', color='red', alpha=0.7)
axes[0, 1].set_title("Offensive Sentiment Trend Over Time", fontsize=14, fontweight='bold')
axes[0, 1].set_xlabel("Date", fontsize=12)
axes[0, 1].set_ylabel("Count of Offensive Tweets", fontsize=12)
axes[0, 1].grid(axis='y', linestyle='--', alpha=0.6)

# --- PLOT 3: Offensive Sentiment Trend Over Time for Top 5 Reply-To Accounts ---
for screen_name in offensive_sentiment_by_top5_reply_time.columns:
    axes[1, 0].plot(
        offensive_sentiment_by_top5_reply_time.index, offensive_sentiment_by_top5_reply_time[screen_name],
        marker='o', linestyle='-', label=screen_name, alpha=0.7
    )
axes[1, 0].set_title("Offensive Sentiment Trend - Top 5 Reply-To Accounts", fontsize=14, fontweight='bold')
axes[1, 0].set_xlabel("Date", fontsize=12)
axes[1, 0].set_ylabel("Count of Offensive Tweets", fontsize=12)
axes[1, 0].legend(title="Screen Name", fontsize=10, title_fontsize=12)
axes[1, 0].grid(axis='y', linestyle='--', alpha=0.6)

# --- PLOT 4: Offensive Sentiment Trend Over Time by Party ---
for party in offensive_sentiment_by_party_time.columns:
    axes[1, 1].plot(
        offensive_sentiment_by_party_time.index, offensive_sentiment_by_party_time[party],
        marker='o', linestyle='-', label=party, alpha=0.7
    )
axes[1, 1].set_title("Offensive Sentiment Trend Over Time by Party", fontsize=14, fontweight='bold')
axes[1, 1].set_xlabel("Date", fontsize=12)
axes[1, 1].set_ylabel("Count of Offensive Tweets", fontsize=12)
axes[1, 1].legend(title="Party", fontsize=10, title_fontsize=12)
axes[1, 1].grid(axis='y', linestyle='--', alpha=0.6)

# Adjust layout
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Load the CSV file
file_path = "/content/drive/MyDrive/new_data_with_sentiment.csv"
df = pd.read_csv(file_path)

# Convert 'date' column to datetime format
df["date"] = pd.to_datetime(df["date"], errors="coerce")

# Get the top 5 most frequent 'in_reply_to_screen_name'
top_5_replies = df['in_reply_to_screen_name'].value_counts().head(5).index
filtered_df = df[df['in_reply_to_screen_name'].isin(top_5_replies)]

# Compute sentiment distribution across top 5 replies
sentiment_distribution = (
    filtered_df.groupby('in_reply_to_screen_name')['sentiment']
    .value_counts(normalize=True)
    .unstack() * 100
)

# Aggregate sentiment over time
sentiment_over_time = df.groupby('date')['sentiment'].mean()

# Aggregate sentiment over time by party
sentiment_by_party_time = df.groupby(['date', 'party'])['sentiment'].mean().unstack()

# --- PLOTTING ---
fig, axes = plt.subplots(3, 1, figsize=(12, 18))  # 3 rows, 1 column

# --- PLOT 1: Sentiment Distribution (Stacked Bar) ---
sentiment_distribution.plot(kind="bar", stacked=True, colormap="coolwarm", ax=axes[0])
axes[0].set_title("Sentiment Distribution Across Top 5 Reply Screen Names", fontsize=14, fontweight="bold")
axes[0].set_xlabel("In Reply To Screen Name", fontsize=12)
axes[0].set_ylabel("Percentage", fontsize=12)
axes[0].legend(title="Sentiment", labels=["NOT", "OFF"])
axes[0].tick_params(axis="x", rotation=45)
axes[0].grid(axis="y", linestyle="--", alpha=0.7)

# --- PLOT 2: Sentiment Trend Over Time ---
axes[1].plot(sentiment_over_time, marker="o", linestyle="-", color="darkblue", alpha=0.7)
axes[1].set_title("Sentiment Trend Over Time", fontsize=14, fontweight="bold")
axes[1].set_xlabel("Date", fontsize=12)
axes[1].set_ylabel("Average Sentiment (0 = Not, 1 = Off)", fontsize=12)
axes[1].tick_params(axis="x", rotation=45)
axes[1].grid(axis="y", linestyle="--", alpha=0.6)

# --- PLOT 3: Sentiment Trend by Party ---
for party in sentiment_by_party_time.columns:
    axes[2].plot(sentiment_by_party_time.index, sentiment_by_party_time[party], marker="o", linestyle="-", label=party, alpha=0.7)

axes[2].set_title("Sentiment Trend Over Time by Party", fontsize=14, fontweight="bold")
axes[2].set_xlabel("Date", fontsize=12)
axes[2].set_ylabel("Average Sentiment", fontsize=12)
axes[2].legend(title="Party", fontsize=10, title_fontsize=12)
axes[2].grid(axis="y", linestyle="--", alpha=0.6)

# Adjust layout
plt.tight_layout()
plt.show()